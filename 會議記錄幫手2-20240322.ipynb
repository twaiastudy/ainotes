{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "from pprint import pp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import functools\n",
    "import platform\n",
    "import argparse\n",
    "from time import time\n",
    "import os\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub,LlamaCpp\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from modelscope.pipelines import pipeline as modelscope_pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "from transformers import AutoProcessor,AutoModelForSpeechSeq2Seq,pipeline\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "from typing import List\n",
    "from punctuators.models import PunctCapSegModelONNX\n",
    "\n",
    "import numpy as np\n",
    "from FlagEmbedding import FlagReranker\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3ab2b",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>1. Function : 移除重複出現的字串</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714df518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_words(text): \n",
    "    pattern = r'(.+?)\\1+'\n",
    "    while True:\n",
    "        new_text = re.sub(pattern, r'\\1', text) \n",
    "        if new_text == text: break \n",
    "        text = new_text \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fddf6",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>2. Initial Whisper Model</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def strtobool(val):\n",
    "    val = val.lower()\n",
    "    if val in ('y', 'yes', 't', 'true', 'on', '1'):\n",
    "        return True\n",
    "    elif val in ('n', 'no', 'f', 'false', 'off', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\"invalid truth value %r\" % (val,))\n",
    "\n",
    "\n",
    "def str_none(val):\n",
    "    if val == 'None':\n",
    "        return None\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "def add_arguments(argname, type, default, help, argparser, **kwargs):\n",
    "    type = strtobool if type == bool else type\n",
    "    type = str_none if type == str else type\n",
    "    argparser.add_argument(\"--\" + argname,\n",
    "                           default=default,\n",
    "                           type=type,\n",
    "                           help=help + ' Default: %(default)s.',\n",
    "                           **kwargs)\n",
    "\n",
    "class infer_obj:\n",
    "    def __init__(self ,audio_path=None ,model_path=None ,use_gpu=None ,language=None,\n",
    "                 num_beams=None ,batch_size=None ,use_compile=None ,task=None,\n",
    "                 assistant_model_path=None ,local_files_only=None ,use_flash_attention_2=None ,\n",
    "                 use_bettertransformer=None,punc_model_name=None):\n",
    "        import sys\n",
    "        sys.argv=['']\n",
    "\n",
    "        parser = argparse.ArgumentParser(description=__doc__)\n",
    "        add_arg = functools.partial(add_arguments, argparser=parser)\n",
    "        add_arg(\"audio_path\",  type=str,  default=\"dataset/test.wav\", help=\"预测的音频路径\")\n",
    "        add_arg(\"model_path\",  type=str,  default=\"openai/whisper-small\", help=\"合并模型的路径，或者是huggingface上模型的名称\")\n",
    "        add_arg(\"use_gpu\",     type=bool, default=True,      help=\"是否使用gpu进行预测\")\n",
    "        add_arg(\"language\",    type=str,  default=\"Chinese\", help=\"设置语言，如果为None则预测的是多语言\")\n",
    "        add_arg(\"num_beams\",   type=int,  default=1,         help=\"解码搜索大小\")\n",
    "        add_arg(\"batch_size\",  type=int,  default=16,        help=\"预测batch_size大小\")\n",
    "        add_arg(\"use_compile\", type=bool, default=False,     help=\"是否使用Pytorch2.0的编译器\")\n",
    "        add_arg(\"task\",        type=str,  default=\"transcribe\", choices=['transcribe', 'translate'], help=\"模型的任务\")\n",
    "        add_arg(\"assistant_model_path\",  type=str,  default=None,  help=\"助手模型，可以提高推理速度，例如openai/whisper-tiny\")\n",
    "        add_arg(\"local_files_only\",      type=bool, default=True,  help=\"是否只在本地加载模型，不尝试下载\")\n",
    "        add_arg(\"use_flash_attention_2\", type=bool, default=False, help=\"是否使用FlashAttention2加速\")\n",
    "        add_arg(\"use_bettertransformer\", type=bool, default=False, help=\"是否使用BetterTransformer加速\")\n",
    "        add_arg(\"punc_model_name\", type=str, default=\"1-800-BAD-CODE/xlm-roberta_punctuation_fullstop_truecase\", help=\"\")\n",
    "        self.args = parser.parse_args()\n",
    "        \n",
    "        if not audio_path is None: self.args.audio_path = audio_path\n",
    "        if not model_path is None: self.args.model_path = model_path\n",
    "        if not use_gpu is None: self.args.use_gpu = use_gpu\n",
    "        if not language is None: self.args.language = language\n",
    "        if not num_beams is None: self.args.num_beams = num_beams\n",
    "        if not batch_size is None: self.args.batch_size = batch_size\n",
    "        if not use_compile is None: self.args.use_compile = use_compile\n",
    "        if not task is None: self.args.task = task\n",
    "        if not assistant_model_path is None: self.args.assistant_model_path = assistant_model_path\n",
    "        if not local_files_only is None: self.args.local_files_only = local_files_only\n",
    "        if not use_flash_attention_2 is None: self.args.use_flash_attention_2 = use_flash_attention_2\n",
    "        if not use_bettertransformer is None: self.args.use_bettertransformer = use_bettertransformer\n",
    "        if not punc_model_name is None: self.args.punc_model_name = punc_model_name\n",
    "        \n",
    "        pp(self.args)\n",
    "                \n",
    "        # 设置设备\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and self.args.use_gpu else \"cpu\"\n",
    "        self.torch_dtype = torch.float16 if torch.cuda.is_available() and self.args.use_gpu else torch.float32\n",
    "        \n",
    "        # 获取Whisper的特征提取器、编码器和解码器\n",
    "        self.processor = AutoProcessor.from_pretrained(self.args.model_path)\n",
    "        \n",
    "        # 获取模型\n",
    "        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "            self.args.model_path, torch_dtype=self.torch_dtype, low_cpu_mem_usage=False, use_safetensors=True,\n",
    "            use_flash_attention_2=self.args.use_flash_attention_2\n",
    "        )\n",
    "        if self.args.use_bettertransformer and not self.args.use_flash_attention_2:\n",
    "            self.model = self.model.to_bettertransformer()\n",
    "        # 使用Pytorch2.0的编译器\n",
    "        if self.args.use_compile:\n",
    "            if torch.__version__ >= \"2\" and platform.system().lower() != 'windows':\n",
    "                self.model = torch.compile(self.model)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # 获取助手模型\n",
    "        self.generate_kwargs_pipeline = None\n",
    "        if self.args.assistant_model_path is not None:\n",
    "            self.assistant_model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.args.assistant_model_path, torch_dtype=self.torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "            )\n",
    "            self.assistant_model.to(self.device)\n",
    "            self.generate_kwargs_pipeline = {\"assistant_model\": self.assistant_model}\n",
    "        \n",
    "        # 获取管道\n",
    "        self.infer_pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                                   model=self.model,\n",
    "                                   tokenizer=self.processor.tokenizer,\n",
    "                                   feature_extractor=self.processor.feature_extractor,\n",
    "                                   max_new_tokens=128,\n",
    "                                   chunk_length_s=30,\n",
    "                                   batch_size=self.args.batch_size,\n",
    "                                   torch_dtype=self.torch_dtype,\n",
    "                                   generate_kwargs=self.generate_kwargs_pipeline,\n",
    "                                   device=self.device)\n",
    "        \n",
    "        # 推理参数\n",
    "        self.generate_kwargs = {\"task\": self.args.task, \"num_beams\": self.args.num_beams}\n",
    "        if self.args.language is not None:\n",
    "            self.generate_kwargs[\"language\"] = self.args.language\n",
    "            \n",
    "        self.punc_model = PunctCapSegModelONNX.from_pretrained(self.args.punc_model_name)\n",
    "           \n",
    "    def infer(self, audio_path=None):\n",
    "        self.result = self.infer_pipe(self.args.audio_path if audio_path is None else audio_path ,\n",
    "                                      return_timestamps=False,\n",
    "                                      generate_kwargs=self.generate_kwargs)\n",
    "        \n",
    "        self.result = self.result['text'].replace('�','').replace(' ','').replace('\\n','')\n",
    "        self.remove_repeated_words()\n",
    "        self.add_punc()\n",
    "        \n",
    "        return self.result\n",
    "    \n",
    "    def remove_repeated_words(self):\n",
    "        try:\n",
    "            self.result = remove_repeated_words(self.result)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def add_punc(self):        \n",
    "        self.result = ''.join(self.punc_model.infer( texts= [self.result] , apply_sbd=True,)[0])\n",
    "  \n",
    "\n",
    "whisper_model = 'openai/whisper-large-v2'\n",
    "whisper = infer_obj(model_path = whisper_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b614255",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>3. Initial LLM</font></h1>\n",
    "<h2><font color='blue'>3-1. Ori : Breeze-7B-Instruct-v1.0-Q5_K_M</font></h2>\n",
    "<h2><font color='blue'>3-2. Fine tune : Breeze-7B-Instruct-v1_0_fine_tuning_20240318_Q5_K_M.gguf</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074456ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(llm_model , temperature=0. , n_gpu_layers=-1):\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    llm = LlamaCpp(model_path=llm_model,\n",
    "                   max_tokens=4096,\n",
    "                   n_gpu_layers=n_gpu_layers,\n",
    "                   n_batch=128,\n",
    "                   callback_manager=callback_manager,\n",
    "                   n_ctx=4096,\n",
    "                   verbose=True,\n",
    "                   temperature=temperature,\n",
    "                   streaming=False)\n",
    "    llm.verbose=False\n",
    "    return llm\n",
    "\n",
    "llm_fine_tune = './Breeze-7B-Instruct-v1_0_fine_tuning_20240318_Q5_K_M.gguf'\n",
    "llm_ori = './breeze-7b-instruct-v1_0-q5_k_m.gguf'\n",
    "\n",
    "langchain_llm = get_llm(llm_model = llm_fine_tune)\n",
    "langchain_llm_ori = get_llm(llm_model = llm_ori)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc4416",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>4. Initial Embedding Model : bge-reranker-large</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BAAI/bge-reranker-large'\n",
    "langchain_embeddings = HuggingFaceEmbeddings(model_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084414a7",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>5. Initial Rerank Model : bge-reranker-large</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3148eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BAAI/bge-reranker-large'\n",
    "reranker = FlagReranker(model_name , use_fp16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3abb3e",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>6. Function : 產生會議逐字稿</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838dda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(audio_file):\n",
    "    transcript = whisper.infer(audio_path = audio_file)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62e294",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>7. Function : 產生會議記錄</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddaff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conference_assistant(texts_ori):\n",
    "\n",
    "    # 找到相關\"句子\"以後, 再往前/後合併的句子數量\n",
    "    forward_num , backward_num = 2 , 2\n",
    "    \n",
    "    rerank_threshold = 0\n",
    "    \n",
    "    def get_split_text(text , chunk_size , chunk_overlap):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap, \n",
    "            separators=[\"\\n\\n\", \"\\n\",\"。\"])\n",
    "        return text_splitter.split_text(text)\n",
    "    \n",
    "    # 用來將llm推論結果做split和清理\n",
    "    replace_punch , split_str , split_str2 = re.compile('\\n|。| ') , re.compile('\\d{1,2}、') , re.compile('。')\n",
    "    def clean_str(tmp):\n",
    "        tmp = split_str.split(replace_punch.sub('' , tmp))\n",
    "        tmp = [i for i in tmp if not i in ['' , '無']]\n",
    "        return tmp\n",
    "    \n",
    "    # 類似項目合併\n",
    "    def merge_similar_items(idx , all_item , sub_prompt):\n",
    "        similar_indexes = np.array(reranker.compute_score([[all_item[idx] ,i] for i in all_item])) > rerank_threshold\n",
    "        remaining_indexes = similar_indexes == False\n",
    "        summarize_item = all_item[similar_indexes].tolist()\n",
    "        if sum(similar_indexes)>1:\n",
    "            summarize_item = check_token_and_summarize(langchain_llm , summarize_item , sub_prompt)\n",
    "        return remaining_indexes , summarize_item\n",
    "    \n",
    "    # 避免token超過, 如果太長就refine摘要\n",
    "    def check_token_and_summarize(langchain_llm , summarize_item , sub_prompt , prefix='<<<' , suffix='>>>'):\n",
    "        ttl_len , first_idx , tmp_topic = len(summarize_item) , 0 , []\n",
    "        last_idx = ttl_len\n",
    "        while first_idx < last_idx:\n",
    "            while langchain_llm.get_num_tokens(f\"{prefix}{','.join(tmp_topic + summarize_item[first_idx:last_idx])}{suffix}{sub_prompt}\") >= langchain_llm.max_tokens:\n",
    "                last_idx -= 1\n",
    "            tmp_topic = clean_str(langchain_llm.invoke(f\"{prefix}{','.join(tmp_topic + summarize_item[first_idx:last_idx])}{suffix}{sub_prompt}\"))\n",
    "            first_idx = last_idx\n",
    "            if first_idx == ttl_len:\n",
    "                summarize_item = tmp_topic\n",
    "                break\n",
    "            else:\n",
    "                last_idx = ttl_len\n",
    "        return summarize_item\n",
    "    \n",
    "    # 過濾重複出現的句子, 最後給使用者確認真實性使用\n",
    "    def filter_duplicates(paragraphs):\n",
    "        final_paragraphs = []\n",
    "        for num , paragraph in enumerate(paragraphs):\n",
    "            main_paragraph , included = paragraph , False\n",
    "            for num2 , check_paragraph in enumerate(paragraphs):\n",
    "                if num2 != num and check_paragraph in main_paragraph: included = True\n",
    "            if not included: final_paragraphs.append(main_paragraph)\n",
    "        final_paragraphs = '    ◎ 摘要段落:\\n' + '\\n'.join([f'        {num+1}、{paragraph}。'.replace('、。','、') for num,paragraph in enumerate(final_paragraphs)]) + '\\n'\n",
    "        return final_paragraphs\n",
    "\n",
    "    # 1. 用 RecursiveCharacterTextSplitter切不同chunk_size\n",
    "    texts = []\n",
    "    for chunk_size,chunk_overlap in [[100,20],[300,50],[500,100]]:\n",
    "        texts+=get_split_text(texts_ori , chunk_size , chunk_overlap)\n",
    "                                     \n",
    "    # 2. 透過fine tune LLM摘要各段落主題\n",
    "    summary_items = []\n",
    "    for text in texts:\n",
    "        summary_items += clean_str(langchain_llm.invoke(f\"<<<{text}>>>這段句子中,提到的<<<主題>>>有哪些?\"))\n",
    "\n",
    "        \n",
    "    # 3. 透過未fine tune LLM 和關鍵字保留/過濾掉非議題的段落\n",
    "    # 關鍵字\n",
    "    command = ['目標', '排程', '議案', '提示', '限時', '提醒', '計畫', '意圖', '負責單位', '提案', '議題',\n",
    "               '布局', '命令', '案件', '宣導','規劃', '策略', '建議', '指示', '佈局', '限期', '決定', '構想',\n",
    "               '負責人', '討論', '方案', '指令', '裁定', '評估', '分析', '活動','定案', '期限', '到期日',\n",
    "               '執行者', '執行官', '負責部門', '決議', '截止日' ,'成立', '整合', '措施', '改善', '改進', '設置',\n",
    "               '合作','舉辦','推動','計劃','應對','準備','建立' ,'協調','重建','應用','審議','推廣','發展','提升',\n",
    "               '非法','支持','處理','管理','行動','設計','部署','任務','巡視','修正','調查','應變','預防','監控','處置','籌備',\n",
    "               '開鑿','事宜','使用','防範','控制','作業','草案','事件','安排','閒置','啟動','分配','需求','協商','接管','修復',\n",
    "               '引進','監督','通知','檢討','資源','利用','整備','工作','補助','津貼','預算','費用','調整','業務','檢查','事務',\n",
    "               '列管','提交','展望','督導','原則','規則','健檢','影響','稽查','稽核','檢測','檢驗','安全','工安','服務','維護',\n",
    "               '生產','預計','預估','估計','報廢','移除','拆除','解除','清除','企劃','編列','管控','專案','演練','加強','價格',\n",
    "               '加強','強化','保養','良率','yield','稼動率','down','setup','巡檢']\n",
    "    \n",
    "    # 排除關鍵字\n",
    "    exclude_keyword = ['頒獎', '獻獎', '表彰', '表揚','獎勵','得獎','頒發']\n",
    "    \n",
    "    is_issue = []\n",
    "    for item in summary_items:\n",
    "        # 當主題段落包含關鍵字、且不包含排除關鍵字就直接保留\n",
    "        if sum([i in item for i in command])>0 and sum([i in item for i in exclude_keyword])==0:\n",
    "            is_issue.append(True)\n",
    "        else:\n",
    "            # 剩下的靠LLM判斷\n",
    "            infer_result = check_token_and_summarize(langchain_llm_ori , command , f'是否隱含在\"\"\"{item}\"\"\"資訊中?請回答是或否,不需回答其它敘述' , prefix='\"\"\"' , suffix='\"\"\"')\n",
    "            is_issue.append(True if '是' in infer_result else False)\n",
    "    is_issue = np.array(is_issue)\n",
    "    summary_items , texts_np = np.array(summary_items)[is_issue] , np.array(texts)[is_issue] \n",
    "    \n",
    "    # 初步濾除後, 剩下的主題 summary_items 作為索引用途\n",
    "    summary_items_merge_similar = summary_items.copy()\n",
    "\n",
    "    # 逐項利用rerank主題計算與其他主題的相關性分數\n",
    "    # 合併相似主題, 再次用LLM摘要\n",
    "    # 這裡做兩次才做的乾淨...\n",
    "    for _ in range(2):\n",
    "        summary_items_len = summary_items_merge_similar.shape[0]\n",
    "        if summary_items_len>1:\n",
    "            reserve_indexes = np.array([True]*summary_items_len)\n",
    "            final_topics = []\n",
    "            for idx in range(summary_items_len):\n",
    "                if reserve_indexes[idx]:\n",
    "                    remaining_indexes , summarize_topic = merge_similar_items(idx , summary_items_merge_similar , \"這段句子中,提到的<<<主題>>>有哪些?\")\n",
    "                    reserve_indexes *= remaining_indexes\n",
    "                    final_topics += summarize_topic\n",
    "            summary_items_merge_similar = np.array(list(set(final_topics)))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 合併後的主題有出現幻覺, 用rerank 和原始文本段落做比較、並過濾\n",
    "    check_ori_doc_score = lambda item: sum(np.array(reranker.compute_score([[item ,i] for i in texts_np])) > rerank_threshold)>0\n",
    "    summary_items_merge_similar = summary_items_merge_similar[[check_ori_doc_score(item) for item in summary_items_merge_similar]]\n",
    "    summary_items_merge_similar = list(set(summary_items_merge_similar))\n",
    "    \n",
    "    # function : 回傳主題對各段落的連結\n",
    "    get_similar_doc = lambda topic: texts_np[np.array(reranker.compute_score([[topic ,i] for i in summary_items])) > rerank_threshold].tolist()\n",
    "\n",
    "    # 逐一處理各主題對應的四大項\n",
    "    items = ['決議' , '計畫' , '期限' , '負責人']\n",
    "    \n",
    "    # 紀錄最後格式化後的結果\n",
    "    summarize_all = ''\n",
    "    \n",
    "    # 開始對不同的主題做四大項摘要\n",
    "    for topic in summary_items_merge_similar:\n",
    "\n",
    "        # 取得主題對應段落\n",
    "        topic_doc = get_similar_doc(topic)\n",
    "\n",
    "        # 加入引用段落回傳用\n",
    "        final_paragraphs = filter_duplicates(topic_doc)\n",
    "\n",
    "        # 開始摘要 '決議' , '計畫' , '期限' , '負責人'相關的資訊\n",
    "        summary = {}\n",
    "        for item in items:\n",
    "\n",
    "            # 摘要指定段落的重點\n",
    "            summarize = check_token_and_summarize(langchain_llm , topic_doc , f'這段句子中,與<<<{topic}>>>相關的<<<{item}>>>有哪些?')\n",
    "\n",
    "            # 如果超過一個項目, 再判斷這些項目是否合併\n",
    "            if len(summarize)>1:\n",
    "                summarize_len = len(summarize)\n",
    "                reserve_indexes = np.array([True]*summarize_len)\n",
    "                final_summarize = []\n",
    "                for idx in range(summarize_len):\n",
    "                    if reserve_indexes[idx]:\n",
    "                        remaining_indexes , summarize_item = merge_similar_items(idx , np.array(summarize) , f\"這段句子中,與<<<{topic}>>>相關的<<<{item}>>>有哪些?\")\n",
    "                        reserve_indexes *= remaining_indexes\n",
    "                        final_summarize += summarize_item\n",
    "                summarize = np.array(list(set(final_summarize)))\n",
    "\n",
    "            # 有找到重點資訊就再用rerank 過濾掉與主題不相關的部分\n",
    "            if len(summarize)>0:\n",
    "                summarize = np.array(summarize)\n",
    "                summarize = summarize[np.array(reranker.compute_score([[topic , doc] for doc in summarize])) > rerank_threshold].reshape(-1)\n",
    "\n",
    "\n",
    "            # 整理成輸出格式\n",
    "            if len(summarize)>0:\n",
    "                tmp = []\n",
    "                for num , i in enumerate(summarize):\n",
    "                    tmp.append(f'        {num+1}、{i}。')\n",
    "                summarize = \"\\n\" + '\\n'.join(tmp) + \"\\n\"\n",
    "            else:\n",
    "                summarize = '無。\\n'\n",
    "\n",
    "            # 填回四大項的位置\n",
    "            summary[item] = summarize\n",
    "\n",
    "\n",
    "        # 整理最終輸出格式\n",
    "        tmp = [f'    ◎ {k}:{summary[k] if summary[k]!=[] else \"無。\"}' for k in summary.keys()]\n",
    "        summarize_all += f'●  討論項目：{topic}\\n' + ''.join(['    ◎ {}:{}'.format(k , summary[k] if summary[k]!=[] else \"無。\\n\") for k in summary.keys()]) + final_paragraphs + '\\n'\n",
    "\n",
    "    return summarize_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f7665",
   "metadata": {},
   "source": [
    "<h1><font color='blue'>8. Function : 會議記錄Gradio </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84475fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "os.environ[\"no_proxy\"] = \"localhost,0.0.0.0,::1\"\n",
    "\n",
    "def transcribe_fn(file):\n",
    "    if not file is None:\n",
    "        text = get_transcript(file)\n",
    "        summary = conference_assistant(text)\n",
    "        return summary,text\n",
    "    else:\n",
    "        return 'Please Upload Audio File ...' ,'Please Upload Audio File ...'\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    gr.Markdown(\"<h1>會議紀錄小幫手AINotes</h1>\")\n",
    "\n",
    "    with gr.Row():\n",
    "        inputs = gr.inputs.Audio(source=\"upload\", optional=True, label=\"Audio file\", type=\"filepath\")\n",
    "    with gr.Row():\n",
    "        inbtw = gr.Button(\"生成會議紀錄\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, min_width=600):\n",
    "            summary = gr.Textbox(label=\"會議記錄\")\n",
    "            transcribe = gr.Textbox(label=\"會議逐字稿\")\n",
    "            \n",
    "    inbtw.click(transcribe_fn, inputs=[inputs], outputs=[summary,transcribe])\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee13b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de779ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec676b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
