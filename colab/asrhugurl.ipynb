{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KATNVadtFca9lT06v_HP7ZYdDzUQjDa-","timestamp":1711125152100}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"22f1c6e205774bffbcfe7429e188a6be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_263c9d16f6134e2e9e596f244ef576d5","IPY_MODEL_a292ab77e55b46c9a85cc825d50d2560","IPY_MODEL_1bbfca6b08364b9f82161c1280eff148"],"layout":"IPY_MODEL_7b6f4a0d69684d738fbada86fcdee53b"}},"263c9d16f6134e2e9e596f244ef576d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9453e3c242f4887b8ad295d963678a5","placeholder":"​","style":"IPY_MODEL_0490bf9f86344df993a31154953a62c4","value":"config.json: 100%"}},"a292ab77e55b46c9a85cc825d50d2560":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_300465019ffa487185042fc9cec4a3e3","max":2281,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c66bafc812ab4e228c5234e3974724e0","value":2281}},"1bbfca6b08364b9f82161c1280eff148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f78aae6dfc64903b61505a3328c4b6e","placeholder":"​","style":"IPY_MODEL_411e878b7daa4d81a07bd0a5148ab804","value":" 2.28k/2.28k [00:00&lt;00:00, 44.9kB/s]"}},"7b6f4a0d69684d738fbada86fcdee53b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9453e3c242f4887b8ad295d963678a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0490bf9f86344df993a31154953a62c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"300465019ffa487185042fc9cec4a3e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66bafc812ab4e228c5234e3974724e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f78aae6dfc64903b61505a3328c4b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"411e878b7daa4d81a07bd0a5148ab804":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28a4a6e188094a5f8ad7c2e4a052018c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00ef5305f80e4e65be6bcfd4e100de0f","IPY_MODEL_4915e43c565b4059b95f13d51ffd7e28","IPY_MODEL_f4e1f25384f34553bbfd3809b0cf41f0"],"layout":"IPY_MODEL_5570b55835f6490a95b136cab33d2e06"}},"00ef5305f80e4e65be6bcfd4e100de0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2df0315cf1344b76af700a36052b4e17","placeholder":"​","style":"IPY_MODEL_11ed027b2616485088debbd2db1efefe","value":"model.safetensors.index.json: 100%"}},"4915e43c565b4059b95f13d51ffd7e28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d6d062dd7724158b7ae39e17c8b1ba0","max":111598,"min":0,"orientation":"horizontal","style":"IPY_MODEL_637d5b8d87c4441a93cc42d23b8a390e","value":111598}},"f4e1f25384f34553bbfd3809b0cf41f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d189990da821470dac08782e40a2f557","placeholder":"​","style":"IPY_MODEL_cbaa7640556444eb997bb3499b95994b","value":" 112k/112k [00:00&lt;00:00, 2.85MB/s]"}},"5570b55835f6490a95b136cab33d2e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2df0315cf1344b76af700a36052b4e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ed027b2616485088debbd2db1efefe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d6d062dd7724158b7ae39e17c8b1ba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"637d5b8d87c4441a93cc42d23b8a390e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d189990da821470dac08782e40a2f557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbaa7640556444eb997bb3499b95994b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11d9dac79b6d4171af8928245358e8ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d935d1875af4a1585e1073f4f253d07","IPY_MODEL_944bfb2ec54547ae8ad885fd0e87f1e5","IPY_MODEL_e6da6f94d9e4439e9ff213453a5357e0"],"layout":"IPY_MODEL_c8c74379df7a41bd9468bb2f8eca7612"}},"3d935d1875af4a1585e1073f4f253d07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8d3346e2b944ae8bc8e2278196a604a","placeholder":"​","style":"IPY_MODEL_037c54aff3c145c7979592868e179e70","value":"Downloading shards:   0%"}},"944bfb2ec54547ae8ad885fd0e87f1e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06dd356e82b4c9999a409aa0e1b790e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f06cee0fd9bc4e6d99a1b06fa9c751fd","value":0}},"e6da6f94d9e4439e9ff213453a5357e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b46e924661140ef96c0c0972470bb8e","placeholder":"​","style":"IPY_MODEL_be775bd59c4941ceb19885b57ee24dcb","value":" 0/2 [00:00&lt;?, ?it/s]"}},"c8c74379df7a41bd9468bb2f8eca7612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d3346e2b944ae8bc8e2278196a604a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"037c54aff3c145c7979592868e179e70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d06dd356e82b4c9999a409aa0e1b790e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f06cee0fd9bc4e6d99a1b06fa9c751fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b46e924661140ef96c0c0972470bb8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be775bd59c4941ceb19885b57ee24dcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55e97d1a4eff4cfcb9785c9411182cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eefd44c7eaf8413ab6d476c5a4f7beb3","IPY_MODEL_3c7ff7ec66bb495885872c97aeff06bb","IPY_MODEL_8e8dab5b71d143e58b6fc60da728a528"],"layout":"IPY_MODEL_4526eae2d47e4bc4b8d9fe0f0e04ca16"}},"eefd44c7eaf8413ab6d476c5a4f7beb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff600d47e0842faa83e4a5ff5f3e69b","placeholder":"​","style":"IPY_MODEL_2105a2f0f0f54bef802207f1d3c266f1","value":"Downloading shards:   0%"}},"3c7ff7ec66bb495885872c97aeff06bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9ac92c434c74222be8a4e69684edae4","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e67a61def69240a1a338b7787e41e0c0","value":0}},"8e8dab5b71d143e58b6fc60da728a528":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e16c49c74c5e4d4992801bf36bc60543","placeholder":"​","style":"IPY_MODEL_cccd2a1104b24f228637e604436618bd","value":" 0/2 [00:00&lt;?, ?it/s]"}},"4526eae2d47e4bc4b8d9fe0f0e04ca16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff600d47e0842faa83e4a5ff5f3e69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2105a2f0f0f54bef802207f1d3c266f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9ac92c434c74222be8a4e69684edae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e67a61def69240a1a338b7787e41e0c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e16c49c74c5e4d4992801bf36bc60543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cccd2a1104b24f228637e604436618bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xAjtcxcpTttO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711337843616,"user_tz":-480,"elapsed":108720,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"5e30cdce-7dbd-4a7d-b1c0-089f6957b15b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytube\n","  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytube\n","Successfully installed pytube-15.0.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m989.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}],"source":["!pip install pytube\n","!pip install torch\n","!pip install transformers"]},{"cell_type":"code","source":["from pytube import YouTube\n","#yt = YouTube('https://www.youtube.com/watch?v=rGjWdhQ5U7g')   # 20231011台南市政府第615次市政會議 直播,大約25 分鐘\n","yt = YouTube('https://www.youtube.com/watch?v=bHcJCp2Fyxs')   # 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介,大約58 分鐘\n","\n","yt.streams.filter().get_audio_only().download(filename='result1.mp3') #檔案要小於25MB\n","# 下載mp3，檔名為test.mp3\n","print('ok!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giipVCqlUvf6","executionInfo":{"status":"ok","timestamp":1711337849291,"user_tz":-480,"elapsed":5679,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"2cfcc258-56fa-48bd-90fd-7d126b35889c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ok!\n"]}]},{"cell_type":"code","source":["#連到到自己的google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxhZSZ06CFg_","executionInfo":{"status":"ok","timestamp":1711126221497,"user_tz":-480,"elapsed":21126,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"cac3a73f-1b59-4e4a-e939-1d545d8b4b2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","!pip install  jiwer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjMXM3Tav_R3","executionInfo":{"status":"ok","timestamp":1711337863748,"user_tz":-480,"elapsed":14461,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"4f72c99c-8a16-459c-d2d3-cfb205f9fabf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jiwer\n","  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n","Successfully installed jiwer-3.0.3 rapidfuzz-3.7.0\n"]}]},{"cell_type":"code","source":["import torch\n","\n","from transformers import pipeline\n","\n","whisper  = pipeline(\"automatic-speech-recognition\",\n","                   # \"openai/whisper-large-v2\",\n","                    \"rogerslee/whisper_finetune\",\n","                    device=\"cuda:0\" ,generate_kwargs  = {\"task\":\"transcribe\", \"language\":\"Chinese\"}) # if you don't have GPU, remove this argument\n","transcription = whisper(\"vadwav/566.wav\",\n","                        chunk_length_s=30)"],"metadata":{"id":"-zJWoIzUCjst"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls *.mp3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbdWRMJ4sKoO","executionInfo":{"status":"ok","timestamp":1711337947712,"user_tz":-480,"elapsed":456,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"5d3b520c-b247-4f04-c34f-7954348470f6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["result1.mp3\n"]}]},{"cell_type":"code","source":["import torch\n","\n","from transformers import pipeline\n","\n","whisper  = pipeline(\"automatic-speech-recognition\",\n","                   # \"openai/whisper-large-v2\",\n","                    \"rogerslee/whisper_finetune\",\n","                    device=\"cuda:0\" ,generate_kwargs  = {\"task\":\"transcribe\", \"language\":\"Chinese\"}) # if you don't have GPU, remove this argument\n","transcription = whisper(\"result1.mp3\",\n","                        chunk_length_s=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["22f1c6e205774bffbcfe7429e188a6be","263c9d16f6134e2e9e596f244ef576d5","a292ab77e55b46c9a85cc825d50d2560","1bbfca6b08364b9f82161c1280eff148","7b6f4a0d69684d738fbada86fcdee53b","b9453e3c242f4887b8ad295d963678a5","0490bf9f86344df993a31154953a62c4","300465019ffa487185042fc9cec4a3e3","c66bafc812ab4e228c5234e3974724e0","4f78aae6dfc64903b61505a3328c4b6e","411e878b7daa4d81a07bd0a5148ab804","28a4a6e188094a5f8ad7c2e4a052018c","00ef5305f80e4e65be6bcfd4e100de0f","4915e43c565b4059b95f13d51ffd7e28","f4e1f25384f34553bbfd3809b0cf41f0","5570b55835f6490a95b136cab33d2e06","2df0315cf1344b76af700a36052b4e17","11ed027b2616485088debbd2db1efefe","3d6d062dd7724158b7ae39e17c8b1ba0","637d5b8d87c4441a93cc42d23b8a390e","d189990da821470dac08782e40a2f557","cbaa7640556444eb997bb3499b95994b","11d9dac79b6d4171af8928245358e8ce","3d935d1875af4a1585e1073f4f253d07","944bfb2ec54547ae8ad885fd0e87f1e5","e6da6f94d9e4439e9ff213453a5357e0","c8c74379df7a41bd9468bb2f8eca7612","c8d3346e2b944ae8bc8e2278196a604a","037c54aff3c145c7979592868e179e70","d06dd356e82b4c9999a409aa0e1b790e","f06cee0fd9bc4e6d99a1b06fa9c751fd","6b46e924661140ef96c0c0972470bb8e","be775bd59c4941ceb19885b57ee24dcb","55e97d1a4eff4cfcb9785c9411182cc5","eefd44c7eaf8413ab6d476c5a4f7beb3","3c7ff7ec66bb495885872c97aeff06bb","8e8dab5b71d143e58b6fc60da728a528","4526eae2d47e4bc4b8d9fe0f0e04ca16","9ff600d47e0842faa83e4a5ff5f3e69b","2105a2f0f0f54bef802207f1d3c266f1","b9ac92c434c74222be8a4e69684edae4","e67a61def69240a1a338b7787e41e0c0","e16c49c74c5e4d4992801bf36bc60543","cccd2a1104b24f228637e604436618bd"]},"id":"5EZ2EWn5U166","executionInfo":{"status":"error","timestamp":1711338017350,"user_tz":-480,"elapsed":1461,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"33a00d6b-af38-4ee0-a907-05435031c214"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22f1c6e205774bffbcfe7429e188a6be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a4a6e188094a5f8ad7c2e4a052018c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d9dac79b6d4171af8928245358e8ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e97d1a4eff4cfcb9785c9411182cc5"}},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"Could not load model rogerslee/whisper_finetune with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSpeechSeq2Seq'>, <class 'transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration'>, <class 'transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForCTC, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n    raise ValueError(\nValueError: Unrecognized configuration class <class 'transformers.models.whisper.configuration_whisper.WhisperConfig'> for this kind of AutoModel: AutoModelForCTC.\nModel type should be one of Data2VecAudioConfig, HubertConfig, MCTCTConfig, SEWConfig, SEWDConfig, UniSpeechConfig, UniSpeechSatConfig, Wav2Vec2Config, Wav2Vec2BertConfig, Wav2Vec2ConformerConfig, WavLMConfig.\n\nwhile loading with AutoModelForSpeechSeq2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 286, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/rogerslee/whisper_finetune/resolve/main/model-00001-of-00002.safetensors\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 398, in cached_file\n    resolved_file = hf_hub_download(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1238, in hf_hub_download\n    metadata = get_hf_file_metadata(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1631, in get_hf_file_metadata\n    r = _request_wrapper(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 385, in _request_wrapper\n    response = _request_wrapper(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 409, in _request_wrapper\n    hf_raise_for_status(response)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 296, in hf_raise_for_status\n    raise EntryNotFoundError(message, response) from e\nhuggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-6600f220-3b7d0f8731852d283673a38a;14e2ccb8-166f-4c8e-a8df-41cbb5ee63a2)\n\nEntry Not Found for url: https://huggingface.co/rogerslee/whisper_finetune/resolve/main/model-00001-of-00002.safetensors.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 561, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3264, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 1038, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 452, in cached_file\n    raise EnvironmentError(\nOSError: rogerslee/whisper_finetune does not appear to have a file named model-00001-of-00002.safetensors. Checkout 'https://huggingface.co/rogerslee/whisper_finetune/main' for available files.\n\nwhile loading with WhisperForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3264, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 1038, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 393, in cached_file\n    raise EnvironmentError(f\"Could not locate {full_filename} inside {path_or_repo_id}.\")\nOSError: Could not locate model-00001-of-00002.safetensors inside rogerslee/whisper_finetune.\n\nwhile loading with TFWhisperForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2795, in from_pretrained\n    raise NotImplementedError(\nNotImplementedError: Support for sharded checkpoints using safetensors is coming soon!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2817, in from_pretrained\n    raise EnvironmentError(\nOSError: Can't load the model for 'rogerslee/whisper_finetune'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'rogerslee/whisper_finetune' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\n\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e50abf3094ec>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m whisper  = pipeline(\"automatic-speech-recognition\",\n\u001b[0m\u001b[1;32m      6\u001b[0m                    \u001b[0;31m# \"openai/whisper-large-v2\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;34m\"rogerslee/whisper_finetune\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_traceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"while loading with {class_name}, an error is thrown:\\n{trace}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0;34mf\"Could not load model {model} with any of the following classes: {class_tuple}. See the original errors:\\n\\n{error}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Could not load model rogerslee/whisper_finetune with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSpeechSeq2Seq'>, <class 'transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration'>, <class 'transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForCTC, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n    raise ValueError(\nValueError: Unrecognized configuration class <class 'transformers.models.whisper.configuration_whisper.WhisperConfig'> for this kind of AutoModel: AutoModelForCTC.\nModel type should be one of Data2VecAudioConfig, HubertConfig, MCTCTConfig, SEWConfig, SEWDConfig, UniSpeechConfig, UniSpeechSatConfig, Wav2Vec2Config, Wav2Vec2BertConfig, Wav2Vec2ConformerConfig, WavLMConfig.\n\nwhile loading with AutoModelForSpeechSeq2Seq, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 286, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/rogerslee/whisper_finetune/resolve/main/model-00001-of-00002.safetensors\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 398, in cached_file\n    resolved_file = hf_hub_download(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1238, in hf_hub_download\n    metadata = get_hf_file_metadata(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1631, in get_hf_file_metadata\n    r = _request_wrapper(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 385, in _request_wrapper\n    response = _request_wrapper(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 409, in _request_wrapper\n    hf_raise_for_status(response)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 296, in hf_raise_for_status\n    raise EntryNotFoundError(message, response) from e\nhuggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-6600f220-3b7d0f8731852d283673a38a;14e2ccb8-166f-4c8e-a8df-41cbb5ee63a2)\n\nEntry Not Found for url: https://huggingface.co/rogerslee/whisper_finetune/resolve/main/model-00001-of-00002.safetensors.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 561, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3264, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 1038, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 452, in cached_file\n    raise EnvironmentError(\nOSError: rogerslee/whisper_finetune does not appear to have a file named model-00001-of-00002.safetensors. Checkout 'https://huggingface.co/rogerslee/whisper_finetune/main' for available files.\n\nwhile loading with WhisperForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3264, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 1038, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 393, in cached_file\n    raise EnvironmentError(f\"Could not locate {full_filename} inside {path_or_repo_id}.\")\nOSError: Could not locate model-00001-of-00002.safetensors inside rogerslee/whisper_finetune.\n\nwhile loading with TFWhisperForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2795, in from_pretrained\n    raise NotImplementedError(\nNotImplementedError: Support for sharded checkpoints using safetensors is coming soon!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 279, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2817, in from_pretrained\n    raise EnvironmentError(\nOSError: Can't load the model for 'rogerslee/whisper_finetune'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'rogerslee/whisper_finetune' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\n\n"]}]},{"cell_type":"code","source":["print(transcription)"],"metadata":{"id":"ESp6dTI3pfBg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711126986230,"user_tz":-480,"elapsed":316,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"a520f04e-de17-4521-c229-b919f1e9ea4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': '在六十六次市政會議之前我們進行獻獎請市長站大台前接受獧獎項沿水水岸公園建置工程，世道一切惡限制白河區拓寬工程，中西區河圍路五段延�富工程式獻獎臺南市公園特色遊戲場規劃設計案由公園科由明亮科園獻獎區域也信義醫院北門分院整建工程由建工科黃裕誠正工程式獻獎請市長及獻獎人員留步公務計八座獎獎水利局各位現長代表回座第一正局共計四座獎獎延航國中附近區大股分或工程是公平之類金職獎由陳書美局長及各位現場代表回座來我們麻煩看前方鏡頭由吳宇芝處長獻獎蔣永康區青春社會住宅類伸展請市長及局長留步，科黨單位共同合影並請各位新黨代表近數字台前那我們請局處長官以及校長站在就是我們第一排合影處那我們各位新黨代表在第二排及第三排因為人數較多麻煩第二排及第三排的長官請偬身包括公務局、包括水利局、包括交通局、包括地政局以及包括都發局、包括教育局、包括文化局以及相關各位學校以及機關的長官、校長、各位好好我想公眾公眾基礎建設規劃完善是一個城市進步的象徵那麼城市因為建築而偉大那民眾因為建築能夠安居能夠樂業偉大的城市是落實宜居以及合宜居住環境那由我們台南市這一次在今年度在國家卓越建設獎中間大放異彩總共獲得三十五座獎杯以及全球卓越建設獎銀獎一座那這個是非常非常高的榮譽榮耀也是非常高的榮譽那這些建築都是一個公眾工程品質的一個表徵也是一個城市在讓城縣在市民朋友還有外來朋友面前一個讓人家覺得這個城市進步的一個表徵那非常謝謝那尤其我們臺南市立圖書館總館新建總館也獲得了還有我們水交涉也獲得了全球逐月獎銀獎一座這點是非常非常不容易的在全球的激烈評比中間雖然不是金獎，但是我們覺得來城市營造以及城市的進步能夠更為彰顯再次感謝也再次祝福我們所有得獎的各個單位、各個機關謝謝各位，市民以各位為榮，謝謝，好再來。確認上次會議議事錄請問各位同仁對於上次會議議事錄有沒有補充�沒有的話就通過報告事項報告事項報告事項一水利局呈報本是沿海地區採部落防護治水黃紅工法對策及成效以北門區及區域為例的報告請楊金豪科長報告時間五分鐘好科長你可以開始了趕趕退朝的影響甚至如果遇到一些颱風或地氣壓也會拉高整個朝位加劇的整個社區排放的困難所以依據網路降下豪大雨這會造成一些積煙水災情我以一百零五年沒積颱風為例在二十四小時降下三百毫米的這個降雨事件就煙水面積就有三百四十公頃主要的煙水範圍包含了北門的井湖、玉港、雪甲的星座端等地勢比較低溫的地區那我們進一步來探討這些社區集水區的分布狀況我們發現整個魚塭跟濃地它所占的比例會比較高那遇到如果遇到一些強降的狀況之下它甚至會加劇而且阻礙整個社區排放的困難我以井湖排水系統為例井湖排水系統它整個集水面積是一千八百五十公頃在魚塭跟農地的比例就高達了八十六趴如果在遇到豪大的情況之下因為農地跟社區它的高差不大雖然它的需用能力有限那如果在豪雨過後魚塭甚至還會加速抽出它的外水抽出它的內水來加劇整個社區排放的困難甚至還會加劇整個社區積煙水的災情有些的社區甚至還會積煙水到兩到三天以上而面對這樣的水文事件來講我們依據以往的治水思維向是排水系統性的治理拓寬或是增大整個抽排能量其實它對於整個集水區的防洪成效是有限的這對於社區的防洪它事實上是緩不及其極所以我們必須要啟動一個治水性思維部落防護而要改善部落防要完成布洛防護必須要有四個要件第一個就是要避免區域排水的外水導灌再來就是要避免社區外的濃田、餘溫或是高地的一個地表水導入到社區再來就是要增強整個社區的一個收集水路能力再來就是設置適宜的抽排工法那以往以前的一個工法包含的就是設置的閘門或是我利用的露堤或是用防風牆來興建二道防線另外還有我們可以改善一些社區的收集水路向說改建那個社區的一個設購系統或是興建鄉韓來提升社區的導排能力另外我們也可以興建像說旭紅池或是錯位站來增加整個拖排的效益簡單講部落房戶要有兩個要件第一個是我要防止區域社區外的外水導入以及提升社區內的一個抽排能力那我接下來會舉兩個部落房戶的案例第一個就是北門舊度石頭社區那北門舊度石頭社區它位在新為位在景湖派系統那它是北林那個巴掌溪那依據網的淹水民心災區的點就是景湖國小那整個井湖就祿石頭排水呢，就祿石頭社區呢？它週邊都是農地若遇到強降雨可能週社區外的高地或農地的地表水就會導到全部導到社區加劇的整個社區的排紅復彈那我們運用剛剛部落防護的思維所設置的八座閘門利用新建防風牆既有的濃度加高以及藉由設置節流向寒四百九十三公尺來避免整個外水的導入另外我也改善了社區內水一百一十公尺的收集水路以及設置四線被擲出的暫體來加速整個內水的個抽排能量那我們整個部落房戶面積大約有二十四公頃那我們也爭取到專案資源七千六百萬元工程也在一百零九年一月竣工那從竣工期間我們歷經的多次的好與事件都有發揮良好的成效有其中以一百一十年去年零八零九在三個小時降下一百五十七毫米的降雨事件來講這皆未有發生積煙水的災情那第二個案例就是雪甲的舊頭港社區那雪甲舊頭港他是位在北門及雪�及血甲的交界那也位在一七一縣以北週邊的使用狀態都是魚塭跟濃地如果遇到豪大雨這些都是會威脅到社區的一個排泡負擔而且這些社區呢地勢相對比較低吧那為運用這個部落防護的工法我設置了一座防控雜門李血衛利用了一七一縣道路以及既有的天南地勢的餘溫堤再利用南一十一線道路加高三百一十一公尺來遞見我的二道防線避免整個農地以及餘溫外水來導入社區另外為整建的社區收集水路四百九十公尺以及我設設兩些每四十四輩體來加速了整個內水的抽盤那整個部落房屋面積上近有十四公頃我們也爭取到專案預算三千三百萬元工程也在去年的一月完工那每歷經的零八零九這個好雨事件也未傳出相關的積煙水災情而在北門血甲類似這種舊頭港以及舊肚子頭社區這樣子的一個水文條件其實我們都有運用部落房戶工法來辦理相關的水利建設例如抽水站例如說排水路整建那自市長上內來其實在部落防護我們就完成了舊肚子頭、北馬雙春、裕港、舊頭港港平和等六個部落防護社區另外我們也完成了新為平和下溪洲三座抽水站也完成了四點二五公里的一個排水路整建另外市府這邊也針對一些其他待改善的地區也一併積極再努力改善例如在北門的三寮灣部落防護、學甲工醫學的抽水站、法源抽水站、載港抽水站等等這是這是我們未來都是積極再努力推動也希望能夠提早發揮這樣的防護成效最後制水工程就像這個捷運站在面對大自然的一個變遷以及應應未來的極端氣候來講我們必須要結合中央的資源、市府的執行地方自主房拆的力量我們結合這三例其力來推動讓市民有感的制水、浸水、清水、活水等優質的環境以上是水利局的報告好謝謝科長接下來請局長補超是的我們那個水利局在我們全室的相關的部落防護工程的部分除了剛才有特別提到的北門血甲之外另外在七股將軍、柳營麻豆後室那個後璧新市等區域大概我們全室也建置了三十一處的部落防護工程那這個整個可以保護的面積有達五百二十八公頃那我們搭配了一個抽排水量大概有九十二點四四十四毋煤死那面對這個極端氣候的一個而不管是抱炒還有一個燃煤我們都已經有發揮很大的一個防污功效那市長上任上來之後我想我們積極的爭取水利署的相關的經費來辦理我們的排水整治、抽水站還有浴紅池那相關的後續的工程呢我們大概也會還有二十五件約二十六億元我想我們會再持續跟水利署來爭取這個相關工程的一個到位以利我們這個應應相關的這個極端氣候所面臨的降雨強度來講我們現在防護韌性更強但是現在提到了水力水力群剛剛提到已經有五億多五億八左右已經完工了想想七億五左右還在施作的就是說我們一方面要再爭取中央的支持另外一方面對於我們施工中一定要如期如止尤其我們今年的訊息已經慢慢慢慢再進入尾聲了那所以要把握這個這個旱季的這個時間能夠加緊加速能夠開始這個施作那以被迷年的訊息來臨前能夠能夠盡可能了完成最大�、最大件數、最大面積的一個保護那謝謝水利局感謝，那謝謝你們也希望說積極的這個積極的協調那其他的局處那也要考量建設那我們因為涉水的建設跟有些大陸建設還有一些這個農業局的地政局的還有包括公務局的一些建設我們希望說有一些排水的設施能夠整合好讓大陸不能夠一挖再挖所以說這個工程要橫向的聯繫整合也要整合好那相關的舉數剛剛唸到的包括工務局、農務局、農業局、地政局甚至交通局在你們在在一些陸設計因為中間也有牽涉到一些比較大的大陸那在設計、在設計局製作的時候或製作之前希望能夠做好橫向的連繫那避免這個工程重複建置或者是說彼此的見解不同然後造成工程資源浪費的這部分務必要減少要最好務必要消除這樣子的一個問題謝謝，好，報告四項二請問一下剛剛大家對於水利局的部落防護這個部落防護治水防洪的工法的工作報告有沒有補充，如果沒有的話就通過。接下來打炸台南隊局處總動員�之下本是藍主詐騙建樹為六都第一本是也成為全臺灣最藍詐騙的城市那本是打炸臺南隊共擬訂七項宣導的策略那首先校園宣導在於培育紡織細胞由教育局來規劃入校的宣導實體課程並且來錄製紡詐騙的影片的教材來教導學生從小培養紡詐騙的意識回家也可以向家長來宣導最新紡詐騙的觀念那入校辦理實體宣導的影片的教材來教導學生從小培養反詐騙的意識回家也可以向家長來宣導最新反詐騙的觀念那錄下辦理實地宣導以及錄製宣導變教的上架那藉由網路宣導我們來傳播反詐騙的即時的訊息那運用本是反詐騙的資料庫由自發中心來辦理網路反詐騙的活動由新聞處來規劃透過廣播、臉書以及在群組還有各公所來推播反詐騙的訊息那我們要透過各種多元的管道想方設法來增加我們宣導的廣度並且達到鋪天蓋地提升宣導的觸及率那就是自發中心辦理網路反詐騙導以及新聞處規劃電台受訪的單元接著我們來辦理藝文宣導要來行銷反炸的文創的人量由文化局以及觀禮局來設計反炸的文創的商品那各個的活動以及景點我們來現場發送或者是販售那藉由這些文創的商品可以來製造民眾的話題尤其在各個的活動以及景點當中來吸引民眾來參與這些反炸片�的活動那這是文化局有加助反詐的標語以及關於舉載吉式活動的照片讓我們來製作應景反詐騙早午晚安的問號圖讓民眾易於接受樂於分享尤其當這些反詐騙的傳播可以融入我們日常的生活的當中那這個是關於製作在地景點的早安圖以及文化局製作英文活動的問號圖要來安排反詐騙的活動讓這些反詐騙的資訊可以貼近我們高齡的長者來打造連長者安心的生活圈那就是在公眾聚點辦理反詐騙的所有的活動以及在轉運站我們來沾貼反詐騙的文宣那接著我們要辦理新進宣導來打造反詐好職局就是由勞工局在各職訊或是徵才的活動以及針對外籍義工來宣導那社會局呢在新新住民的結訊活動來辦理宣導讓即將踏入職場的新鮮人求職就業不會受騙也讓這些新住民有一個友善異居的城市那就是在職訊活動及在新住民活動我們前往辦理反詐騙宣導那最後呢我們要來加強社區的宣導要來連結反詐好處逼由環保局來後製市長反炸片的錄音檔那有垃圾車在區域的時候我們沿途來放送並且在各公所、各林里辦理活動的時候我們前往在地的社區的宣導那我們以達到能夠遞談式的普及並深入我們的林里社區並且我們要來鼓勵我們的林里的鄉親來參與並建構反炸的區域的連防那這是市長在入室的車車反炸營堂以及區公所在活動的時候我們辦理反炸的宣導的活動那所謂資安工作沒有最好只有更好讓我們藉由各取助的通力合作並且來參與反炸宣導團的各式的宣導的策略我們要共同來守護大台南市民的財產安全那也唯有我們將打炸台南隊做得更好才能讓我們市民朋友們過得更好這個防治詐騙的工作能夠伸入社區跟我們的市民鄉親所以代副市長也主持了兩次的會議那事實上在今年的一月份市長就只是我們臺南市成立化局處的反炸宣導工作平台那已經他舉為秘書單位動員市府各局處超前部屬來共同合作推動反炸宣導工作那行政院在今年的七月十五號也正式核定了新世代打擊炸氣略行動綱�因為我們這個打炸台南隊啊今年我們統計一到九月份在欄主詐騙的總件數我們達到一千八百九十七件較去年同期增加的七百八十一件整體提高了百分之六十九點九八將近七成那欄主的金額也高達五億一千一百六十四萬元比去年同期增加的兩億五千一百三十八萬元提高將近一倍提高到百分之九十六點五九這都是我們打在台南隊的一個實際的量實際上遭受損失那麼除了這個部分之外當然除了第一線的防詐之外我們也跟許多社團來合作讓民眾有這個有這個警覺性和反詐騙的意識好那我們請民政局、勞工局、原民會等等和警察局合作將宣導融入日常活動之中謝謝各位啊，謝謝公務局擬拒中西區協進國小協進國民小學前報會拆除未育使用連線至協進人行路橋一案請審議案說明本案裡報會拆除之建物其入葬日期主體構造使用連線及拆除標地價值如復建直接人行天橋位處中西區金華路四段與和平街一百一十八巷交叉口附近因地源關係上下學十段交通流量壅塞且據協進國民小學家長會反映常有交通事故幫邀請本府交通局會看後建議拆除人行路橋並於該路口設置交通號制經一規定報請主管機關核定擬一本事是有財產管理資治條例第六十五條第一項第三款規定辦理本案之報廢程序提請審議好請問各位對於拆除協信國小前的未育使用連線的人行路橋一案有沒有補充一件沒有的話就通過送臺南市審計出審核討論事項二之五案是店賦案總店賦金額是台幣一千兩百六十五萬六千元整那提案機關有社會局三案環境保護局一案計畫名稱跟店賦金額就請參閱書面說明討論事項二之五案你請轉移提送市議會審議先請辦理店舖四一百一十二年度最佳簡預算時再於整鎮提請審議請問各位同仁對於討論事項第二案到第五案的這五項這個店舖案有沒有補充一件沒有的話就通宋世義會審議討論四項六為表揚何國朝先生長年畢生致力於宋江鎮記憶文化推動培育宋江鎮意識及人才星火相傳對於台灣宋江鎮記憶文化資傳者不以以以於勵志精神民政局擬本府表揚卓越是民實�要點第二點第四款之規定頒發表揚撞與卓越市民議案提前審議尊明斷議請參議案具體設計略數如覆件好請問各位同仁對於表揚何國樵宣生致力於宋江正記憶文化推動頒發表揚撞與卓越市民議案有沒有補充意見？如果沒有的話就通過擇期辦法臨時動議請問各位同仁有沒有臨時動議提出？如果沒有的話謝謝各位了山會'}\n"]}]},{"cell_type":"code","source":["transcription['text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"id":"ina1Wp6qH1Vg","executionInfo":{"status":"ok","timestamp":1711127136731,"user_tz":-480,"elapsed":337,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"88970f7a-61c7-4c14-8632-be4036ecf613"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'在六十六次市政會議之前我們進行獻獎請市長站大台前接受獧獎項沿水水岸公園建置工程，世道一切惡限制白河區拓寬工程，中西區河圍路五段延�富工程式獻獎臺南市公園特色遊戲場規劃設計案由公園科由明亮科園獻獎區域也信義醫院北門分院整建工程由建工科黃裕誠正工程式獻獎請市長及獻獎人員留步公務計八座獎獎水利局各位現長代表回座第一正局共計四座獎獎延航國中附近區大股分或工程是公平之類金職獎由陳書美局長及各位現場代表回座來我們麻煩看前方鏡頭由吳宇芝處長獻獎蔣永康區青春社會住宅類伸展請市長及局長留步，科黨單位共同合影並請各位新黨代表近數字台前那我們請局處長官以及校長站在就是我們第一排合影處那我們各位新黨代表在第二排及第三排因為人數較多麻煩第二排及第三排的長官請偬身包括公務局、包括水利局、包括交通局、包括地政局以及包括都發局、包括教育局、包括文化局以及相關各位學校以及機關的長官、校長、各位好好我想公眾公眾基礎建設規劃完善是一個城市進步的象徵那麼城市因為建築而偉大那民眾因為建築能夠安居能夠樂業偉大的城市是落實宜居以及合宜居住環境那由我們台南市這一次在今年度在國家卓越建設獎中間大放異彩總共獲得三十五座獎杯以及全球卓越建設獎銀獎一座那這個是非常非常高的榮譽榮耀也是非常高的榮譽那這些建築都是一個公眾工程品質的一個表徵也是一個城市在讓城縣在市民朋友還有外來朋友面前一個讓人家覺得這個城市進步的一個表徵那非常謝謝那尤其我們臺南市立圖書館總館新建總館也獲得了還有我們水交涉也獲得了全球逐月獎銀獎一座這點是非常非常不容易的在全球的激烈評比中間雖然不是金獎，但是我們覺得來城市營造以及城市的進步能夠更為彰顯再次感謝也再次祝福我們所有得獎的各個單位、各個機關謝謝各位，市民以各位為榮，謝謝，好再來。確認上次會議議事錄請問各位同仁對於上次會議議事錄有沒有補充�沒有的話就通過報告事項報告事項報告事項一水利局呈報本是沿海地區採部落防護治水黃紅工法對策及成效以北門區及區域為例的報告請楊金豪科長報告時間五分鐘好科長你可以開始了趕趕退朝的影響甚至如果遇到一些颱風或地氣壓也會拉高整個朝位加劇的整個社區排放的困難所以依據網路降下豪大雨這會造成一些積煙水災情我以一百零五年沒積颱風為例在二十四小時降下三百毫米的這個降雨事件就煙水面積就有三百四十公頃主要的煙水範圍包含了北門的井湖、玉港、雪甲的星座端等地勢比較低溫的地區那我們進一步來探討這些社區集水區的分布狀況我們發現整個魚塭跟濃地它所占的比例會比較高那遇到如果遇到一些強降的狀況之下它甚至會加劇而且阻礙整個社區排放的困難我以井湖排水系統為例井湖排水系統它整個集水面積是一千八百五十公頃在魚塭跟農地的比例就高達了八十六趴如果在遇到豪大的情況之下因為農地跟社區它的高差不大雖然它的需用能力有限那如果在豪雨過後魚塭甚至還會加速抽出它的外水抽出它的內水來加劇整個社區排放的困難甚至還會加劇整個社區積煙水的災情有些的社區甚至還會積煙水到兩到三天以上而面對這樣的水文事件來講我們依據以往的治水思維向是排水系統性的治理拓寬或是增大整個抽排能量其實它對於整個集水區的防洪成效是有限的這對於社區的防洪它事實上是緩不及其極所以我們必須要啟動一個治水性思維部落防護而要改善部落防要完成布洛防護必須要有四個要件第一個就是要避免區域排水的外水導灌再來就是要避免社區外的濃田、餘溫或是高地的一個地表水導入到社區再來就是要增強整個社區的一個收集水路能力再來就是設置適宜的抽排工法那以往以前的一個工法包含的就是設置的閘門或是我利用的露堤或是用防風牆來興建二道防線另外還有我們可以改善一些社區的收集水路向說改建那個社區的一個設購系統或是興建鄉韓來提升社區的導排能力另外我們也可以興建像說旭紅池或是錯位站來增加整個拖排的效益簡單講部落房戶要有兩個要件第一個是我要防止區域社區外的外水導入以及提升社區內的一個抽排能力那我接下來會舉兩個部落房戶的案例第一個就是北門舊度石頭社區那北門舊度石頭社區它位在新為位在景湖派系統那它是北林那個巴掌溪那依據網的淹水民心災區的點就是景湖國小那整個井湖就祿石頭排水呢，就祿石頭社區呢？它週邊都是農地若遇到強降雨可能週社區外的高地或農地的地表水就會導到全部導到社區加劇的整個社區的排紅復彈那我們運用剛剛部落防護的思維所設置的八座閘門利用新建防風牆既有的濃度加高以及藉由設置節流向寒四百九十三公尺來避免整個外水的導入另外我也改善了社區內水一百一十公尺的收集水路以及設置四線被擲出的暫體來加速整個內水的個抽排能量那我們整個部落房戶面積大約有二十四公頃那我們也爭取到專案資源七千六百萬元工程也在一百零九年一月竣工那從竣工期間我們歷經的多次的好與事件都有發揮良好的成效有其中以一百一十年去年零八零九在三個小時降下一百五十七毫米的降雨事件來講這皆未有發生積煙水的災情那第二個案例就是雪甲的舊頭港社區那雪甲舊頭港他是位在北門及雪�及血甲的交界那也位在一七一縣以北週邊的使用狀態都是魚塭跟濃地如果遇到豪大雨這些都是會威脅到社區的一個排泡負擔而且這些社區呢地勢相對比較低吧那為運用這個部落防護的工法我設置了一座防控雜門李血衛利用了一七一縣道路以及既有的天南地勢的餘溫堤再利用南一十一線道路加高三百一十一公尺來遞見我的二道防線避免整個農地以及餘溫外水來導入社區另外為整建的社區收集水路四百九十公尺以及我設設兩些每四十四輩體來加速了整個內水的抽盤那整個部落房屋面積上近有十四公頃我們也爭取到專案預算三千三百萬元工程也在去年的一月完工那每歷經的零八零九這個好雨事件也未傳出相關的積煙水災情而在北門血甲類似這種舊頭港以及舊肚子頭社區這樣子的一個水文條件其實我們都有運用部落房戶工法來辦理相關的水利建設例如抽水站例如說排水路整建那自市長上內來其實在部落防護我們就完成了舊肚子頭、北馬雙春、裕港、舊頭港港平和等六個部落防護社區另外我們也完成了新為平和下溪洲三座抽水站也完成了四點二五公里的一個排水路整建另外市府這邊也針對一些其他待改善的地區也一併積極再努力改善例如在北門的三寮灣部落防護、學甲工醫學的抽水站、法源抽水站、載港抽水站等等這是這是我們未來都是積極再努力推動也希望能夠提早發揮這樣的防護成效最後制水工程就像這個捷運站在面對大自然的一個變遷以及應應未來的極端氣候來講我們必須要結合中央的資源、市府的執行地方自主房拆的力量我們結合這三例其力來推動讓市民有感的制水、浸水、清水、活水等優質的環境以上是水利局的報告好謝謝科長接下來請局長補超是的我們那個水利局在我們全室的相關的部落防護工程的部分除了剛才有特別提到的北門血甲之外另外在七股將軍、柳營麻豆後室那個後璧新市等區域大概我們全室也建置了三十一處的部落防護工程那這個整個可以保護的面積有達五百二十八公頃那我們搭配了一個抽排水量大概有九十二點四四十四毋煤死那面對這個極端氣候的一個而不管是抱炒還有一個燃煤我們都已經有發揮很大的一個防污功效那市長上任上來之後我想我們積極的爭取水利署的相關的經費來辦理我們的排水整治、抽水站還有浴紅池那相關的後續的工程呢我們大概也會還有二十五件約二十六億元我想我們會再持續跟水利署來爭取這個相關工程的一個到位以利我們這個應應相關的這個極端氣候所面臨的降雨強度來講我們現在防護韌性更強但是現在提到了水力水力群剛剛提到已經有五億多五億八左右已經完工了想想七億五左右還在施作的就是說我們一方面要再爭取中央的支持另外一方面對於我們施工中一定要如期如止尤其我們今年的訊息已經慢慢慢慢再進入尾聲了那所以要把握這個這個旱季的這個時間能夠加緊加速能夠開始這個施作那以被迷年的訊息來臨前能夠能夠盡可能了完成最大�、最大件數、最大面積的一個保護那謝謝水利局感謝，那謝謝你們也希望說積極的這個積極的協調那其他的局處那也要考量建設那我們因為涉水的建設跟有些大陸建設還有一些這個農業局的地政局的還有包括公務局的一些建設我們希望說有一些排水的設施能夠整合好讓大陸不能夠一挖再挖所以說這個工程要橫向的聯繫整合也要整合好那相關的舉數剛剛唸到的包括工務局、農務局、農業局、地政局甚至交通局在你們在在一些陸設計因為中間也有牽涉到一些比較大的大陸那在設計、在設計局製作的時候或製作之前希望能夠做好橫向的連繫那避免這個工程重複建置或者是說彼此的見解不同然後造成工程資源浪費的這部分務必要減少要最好務必要消除這樣子的一個問題謝謝，好，報告四項二請問一下剛剛大家對於水利局的部落防護這個部落防護治水防洪的工法的工作報告有沒有補充，如果沒有的話就通過。接下來打炸台南隊局處總動員�之下本是藍主詐騙建樹為六都第一本是也成為全臺灣最藍詐騙的城市那本是打炸臺南隊共擬訂七項宣導的策略那首先校園宣導在於培育紡織細胞由教育局來規劃入校的宣導實體課程並且來錄製紡詐騙的影片的教材來教導學生從小培養紡詐騙的意識回家也可以向家長來宣導最新紡詐騙的觀念那入校辦理實體宣導的影片的教材來教導學生從小培養反詐騙的意識回家也可以向家長來宣導最新反詐騙的觀念那錄下辦理實地宣導以及錄製宣導變教的上架那藉由網路宣導我們來傳播反詐騙的即時的訊息那運用本是反詐騙的資料庫由自發中心來辦理網路反詐騙的活動由新聞處來規劃透過廣播、臉書以及在群組還有各公所來推播反詐騙的訊息那我們要透過各種多元的管道想方設法來增加我們宣導的廣度並且達到鋪天蓋地提升宣導的觸及率那就是自發中心辦理網路反詐騙導以及新聞處規劃電台受訪的單元接著我們來辦理藝文宣導要來行銷反炸的文創的人量由文化局以及觀禮局來設計反炸的文創的商品那各個的活動以及景點我們來現場發送或者是販售那藉由這些文創的商品可以來製造民眾的話題尤其在各個的活動以及景點當中來吸引民眾來參與這些反炸片�的活動那這是文化局有加助反詐的標語以及關於舉載吉式活動的照片讓我們來製作應景反詐騙早午晚安的問號圖讓民眾易於接受樂於分享尤其當這些反詐騙的傳播可以融入我們日常的生活的當中那這個是關於製作在地景點的早安圖以及文化局製作英文活動的問號圖要來安排反詐騙的活動讓這些反詐騙的資訊可以貼近我們高齡的長者來打造連長者安心的生活圈那就是在公眾聚點辦理反詐騙的所有的活動以及在轉運站我們來沾貼反詐騙的文宣那接著我們要辦理新進宣導來打造反詐好職局就是由勞工局在各職訊或是徵才的活動以及針對外籍義工來宣導那社會局呢在新新住民的結訊活動來辦理宣導讓即將踏入職場的新鮮人求職就業不會受騙也讓這些新住民有一個友善異居的城市那就是在職訊活動及在新住民活動我們前往辦理反詐騙宣導那最後呢我們要來加強社區的宣導要來連結反詐好處逼由環保局來後製市長反炸片的錄音檔那有垃圾車在區域的時候我們沿途來放送並且在各公所、各林里辦理活動的時候我們前往在地的社區的宣導那我們以達到能夠遞談式的普及並深入我們的林里社區並且我們要來鼓勵我們的林里的鄉親來參與並建構反炸的區域的連防那這是市長在入室的車車反炸營堂以及區公所在活動的時候我們辦理反炸的宣導的活動那所謂資安工作沒有最好只有更好讓我們藉由各取助的通力合作並且來參與反炸宣導團的各式的宣導的策略我們要共同來守護大台南市民的財產安全那也唯有我們將打炸台南隊做得更好才能讓我們市民朋友們過得更好這個防治詐騙的工作能夠伸入社區跟我們的市民鄉親所以代副市長也主持了兩次的會議那事實上在今年的一月份市長就只是我們臺南市成立化局處的反炸宣導工作平台那已經他舉為秘書單位動員市府各局處超前部屬來共同合作推動反炸宣導工作那行政院在今年的七月十五號也正式核定了新世代打擊炸氣略行動綱�因為我們這個打炸台南隊啊今年我們統計一到九月份在欄主詐騙的總件數我們達到一千八百九十七件較去年同期增加的七百八十一件整體提高了百分之六十九點九八將近七成那欄主的金額也高達五億一千一百六十四萬元比去年同期增加的兩億五千一百三十八萬元提高將近一倍提高到百分之九十六點五九這都是我們打在台南隊的一個實際的量實際上遭受損失那麼除了這個部分之外當然除了第一線的防詐之外我們也跟許多社團來合作讓民眾有這個有這個警覺性和反詐騙的意識好那我們請民政局、勞工局、原民會等等和警察局合作將宣導融入日常活動之中謝謝各位啊，謝謝公務局擬拒中西區協進國小協進國民小學前報會拆除未育使用連線至協進人行路橋一案請審議案說明本案裡報會拆除之建物其入葬日期主體構造使用連線及拆除標地價值如復建直接人行天橋位處中西區金華路四段與和平街一百一十八巷交叉口附近因地源關係上下學十段交通流量壅塞且據協進國民小學家長會反映常有交通事故幫邀請本府交通局會看後建議拆除人行路橋並於該路口設置交通號制經一規定報請主管機關核定擬一本事是有財產管理資治條例第六十五條第一項第三款規定辦理本案之報廢程序提請審議好請問各位對於拆除協信國小前的未育使用連線的人行路橋一案有沒有補充一件沒有的話就通過送臺南市審計出審核討論事項二之五案是店賦案總店賦金額是台幣一千兩百六十五萬六千元整那提案機關有社會局三案環境保護局一案計畫名稱跟店賦金額就請參閱書面說明討論事項二之五案你請轉移提送市議會審議先請辦理店舖四一百一十二年度最佳簡預算時再於整鎮提請審議請問各位同仁對於討論事項第二案到第五案的這五項這個店舖案有沒有補充一件沒有的話就通宋世義會審議討論四項六為表揚何國朝先生長年畢生致力於宋江鎮記憶文化推動培育宋江鎮意識及人才星火相傳對於台灣宋江鎮記憶文化資傳者不以以以於勵志精神民政局擬本府表揚卓越是民實�要點第二點第四款之規定頒發表揚撞與卓越市民議案提前審議尊明斷議請參議案具體設計略數如覆件好請問各位同仁對於表揚何國樵宣生致力於宋江正記憶文化推動頒發表揚撞與卓越市民議案有沒有補充意見？如果沒有的話就通過擇期辦法臨時動議請問各位同仁有沒有臨時動議提出？如果沒有的話謝謝各位了山會'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["with open('566_323.txt', 'w',encoding='utf8') as f:\n","    f.write(transcription['text'])"],"metadata":{"id":"pBw8nxTdINs2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transcription['text']"],"metadata":{"id":"b-5ia9bBIrga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","from transformers import pipeline\n","\n","whisper  = pipeline(\"automatic-speech-recognition\",\n","                   # \"openai/whisper-large-v2\",\n","                    \"seiching/whisper-large-seiching\",\n","                    device=\"cuda:0\" ,generate_kwargs  = {\"task\":\"transcribe\", \"language\":\"Chinese\"}) # if you don't have GPU, remove this argument\n","transcription = whisper(\"vadwav/597.wav\",\n","                        chunk_length_s=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAzLEgeUIyQN","executionInfo":{"status":"ok","timestamp":1711127826701,"user_tz":-480,"elapsed":455677,"user":{"displayName":"twaiastudy","userId":"15814458144084920053"}},"outputId":"e121d5f2-5743-4ba6-ce14-fcf5a6db0ac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["with open('597_323.txt', 'w',encoding='utf8') as f:\n","    f.write(transcription['text'])"],"metadata":{"id":"aIQYjIoDI7m3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","from transformers import pipeline\n","\n","whisper  = pipeline(\"automatic-speech-recognition\",\n","                   # \"openai/whisper-large-v2\",\n","                    \"seiching/whisper-large-seiching\",\n","                    device=\"cuda:0\" ,generate_kwargs  = {\"task\":\"transcribe\", \"language\":\"Chinese\"}) # if you don't have GPU, remove this argument\n","transcription = whisper(\"vadwav/609.wav\",\n","                        chunk_length_s=30)"],"metadata":{"id":"TTCerQleI_lC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('609_323.txt', 'w',encoding='utf8') as f:\n","    f.write(transcription['text'])"],"metadata":{"id":"sDfABjAKJLUG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","from transformers import pipeline\n","\n","whisper  = pipeline(\"automatic-speech-recognition\",\n","                   # \"openai/whisper-large-v2\",\n","                    \"seiching/whisper-large-seiching\",\n","                    device=\"cuda:0\" ,generate_kwargs  = {\"task\":\"transcribe\", \"language\":\"Chinese\"}) # if you don't have GPU, remove this argument\n","transcription = whisper(\"vadwav/626.wav\",\n","                        chunk_length_s=30)"],"metadata":{"id":"huoVnFBEJTIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('626_323.txt', 'w',encoding='utf8') as f:\n","    f.write(transcription['text'])"],"metadata":{"id":"wBCqm4EZJckh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(transcription)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1eCOSr5WwXV","executionInfo":{"status":"ok","timestamp":1708502283432,"user_tz":-480,"elapsed":7,"user":{"displayName":"nctuhack3","userId":"16262766100182643838"}},"outputId":"275fba4b-f8a8-4ad7-a7b1-8c8cc7054130"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': '你怎麼不說說你怎麼不說說你怎麼不說說你怎麼不說說你怎麼不說說你怎麼不說說好，那我們今天的市政會議就正式開始號確認上次會議議事錄臨時管理自治條例草案報告請成員和科長報告時間五分鐘為近年排放的市的整個今年排放量為平均量為每個人十一點九八公噸。排放量為六度的第三低，異低於全國的排放量。台南市是全國第一個公告台南市地上永續之日條例的城市。我們首先在一百一一百零一一年公告規範了八百k晚上用電大火需要設設燦光電而且指定特定示範區例如九份十分高點設定區為燦光電設定區經過各取出的努力跟協助之下台南市問題排放量中二零一零一二零一零前已經九年下降應減量十四百分以上但是我們談是應應整個國家企業的政策、經理的政策一樣以二零五年為目標因此我們將進行城市資調例修訂為進行永續城市管理資調例好該條例該條例經過整個市府已召開市場次以上的跨取出會議而且對外應針對相關議案官企業召開十三場式的一些公聽會跟演商會目前的資治條例的話我們參考依照參考原本的資治條例為基準目前條例總共分成七個章節四十九條第一章部分第一章主要是規範了各主管機管全者用電單我需要設定一定太陽光電的比例還有一些真的建築部分工務局有規範了一些新建建築打在一定規模以上需要申請人效評估還有交通局會針對一些交通、應聚、地太應聚進行的推廣然後在第三章的部分第三章主要為企業並兼調永續推動的專帳主要規劃規範的廢棄物處理源頭減量為目標其中比較重要是我們要求規範環保局會要求規範要求一些事業提出廢棄物減量的計畫另外呢在水利局方面有規範了推廣及鼓勵企業要使用載水可以達到整個水源跟廢棄物的循環第五章為近年綠生活的推廣的運動這個專案跟民眾生活比較相關從食衣、塑形、遇熱各方面進行推動其中比較重要是規範在一百一十五年起臺南市的觀光旅館業在一百一十五年起不得免費提供一次性的用品另外在各個機關、例如學校部門要推動遞遞看的校園的運作第二章主要是法者第二章的法者只要針對前述的相關規定訂定相關法者從一千一千兩百元到十萬元不等跟各位報告一下我們經過十三常設的相關的會議萬一屆民眾比較關心有四大議題主要為推動再三人也推動涉及到經發跟公務還有一些禁職務人效的揭露主要涉及到公務局的部分還有一些地攤應居的推廣然後主要涉及交通跟環保然後檢討都市規劃就是然後後續整個資調理皆相關利案的關線有敘述說該條例後續會總共會有十幾個需要另外公告希望各位局處先預為準備然後最後經過今天在市政會中也會針對該條例的一些提案那今天如果市政會通過之後環保局會將立即將條例送到市政會去審議以上報告，謝謝！其實是全臺灣局處的互動、合作最強的因為當時我是承辦人我們當時在評選的時候幾乎是沒有疑慮、疑義的一致通過那個委員都認同說臺南整個在運作上非常順暢所以以這個為基礎其實敬領永續這一塊工作其實其實在台南推展應該也是很容易就是大家在合作上應該是會很順利的主要這個條例送了之後我們還有十六個相關的執法要在半年到一年內趕快把他訂定所以就相關的局住可能要盡量來協助環保局還是會擔任這個整個計畫的窗口我們會有專人甚至我們市長也同意我們有個專門的科現在也已經成立了所以在這個會期送到議會之後如果審議通過之後我們會全力來協助各局處來推動這樣的事務因為畢竟最後的資料呈現還是要環保局主政，但這是全台人事政府甚至全台人事的事情那我記得在昨天蔡總統的國慶演說中也提到了推動進林的腳步必須加快而且不能走回頭路那也知道COPE 26、COPE 27年國氣候變遷公約的一個會員國的會議一再強調這個淨零碳排的重要性永續性那也逐漸在許多國家開始落實包括碳權的取得以及碳交易以及其他的這個近臨探排的一些相關措施過去是要節能減碳那更進一步在近臨探排的這個道路中我想說我們沒有落後的權力那剛剛局長也提過在民國一百年、二零一一年的時候事實上我們已經有不錯的成果那這個更需要我們現在更需要延續這個成果那這個條例這個自治條例有六大核心目標剛剛已經提過了那我希望說包括我們自己這個部分都必須要能夠在行政上、在政府的作為上、在行政裁量上先強先落實當然要等到議會通過自治條例了但是我們不是等到自治條例之後通過我們才開始做有一些部分我們是否能夠自己先做的我們一定要做包括現在我們已經做的另外呢在大眾運聚的推廣以及共享運聚的推動上面包括共享單車啦或共享機車啦共享機車這些都是能夠減少碳足積能夠減碳包括停車位的加強設置減少在路途中為了找車位所哀奪的時間跟溫室氣體的排放這些都是能夠相對地減少碳排能夠進一步達到近臨好的這個一些作為拘之拘折或者是大體的方向我們都要朝向這個近臨永續的程式來發展那這些也期望大家一起努力好謝謝環保局請問有沒有補充意見沒有的話就通過備查討論事項一環境保護局女句台南市進行永續程式管理次次條例草案提請審議說明本草案液金本府法規會第八十四次及八十五次會議決議修正通過而為有效減緩氣候變遷之影響打造本是為聚調適任性之永續程式直線溫室氣體盡林排放確保市民生活品質社會進步及環境維護原理制定台南市淨領永續程式管理自治條例草案共分為七張條文共計四十九條來剛剛這有報告過了好請問一下各位同仁對於討論事項一環保局索擬句談談是建議永續城市管理自治條例草案有沒有補充意見沒有沒有就通過送�案提請審議說明一至五請參閱，自將該修正草案應付提請審議提問各位同仁對於討論事項二對於剛剛所唸出來的這些個戶政事務所編制表有沒有普通意見？這個修正草案如果沒有意見的話就通過依法之作業程序辦理發布而且送全局部備場討論事項三民政局擬句臺南市安南區公所編製表修正草案提請審議說明一二請參院將該修正草案應付提請審議好請問各位同仁對於民政局所擬句臺市安南區域公所編製表修正草案有沒有普通意見？沒有沒有就通過依法制作業程序辦理發布並且送程序部備案備查討論事項四文化局擬句台南市文化資產管理處組織歸層及編製表修正草案提請審議說明請參院自將該修正草案應付提請審議好請問各位同仁對文化局所擬句談談是文化資產管理處組織歸層及編製表修正草案有沒有補充一件沒有沒有就沒有的話就通過依法製作程序辦理發布並送考試驗全書部備查討論事項五至二十一案為電賦案總電賦金額四億兩千八百八十九萬八千元一案機關計畫名稱電賦金額請參閱說明討論事項五至二十一案你請准以提送案有沒有普春意見？沒有沒有的話就通過送適宜會時動議有問各位有沒有臨時動議提出好那謝謝謝謝各位我想這個是連續假期好之後的第一次市政會議也是好我們這個市政會議好在上午剛恢復上班之後那希望說大家能夠這個感謝各位在連續假期中間對於維護市容以及相關的防疫作為以及相關的治安維護所作的努力感謝警察局以及環保局、衛生局還有各個局處的努力那今年的國慶晚會也能夠圓滿完成這個總統以及性籌處主任委員、有院長以及相關當天蒞臨的長官都對於談事的準備工作相當大衛表示高度的讚許和滿意尤其雖然中間有下雨但會場的這個包括節目的進行、包括秩序的維持都能夠順利這個會後場地由於是軍事基地也感謝國空軍第一戰術連隊在市府、各位同仁、包括民政局、各位同仁、大家的努力下很快就恢復這個正街�那能夠還軍事基地一個重要的一個原來的面貌非常謝謝，那現場的疏散以及道路品質的維護都謝謝各位。那這個讓這個國家的慶典、重要的慶典能夠順利圓滿。好，那我們在過去也主辦過國慶煙火也是相當的順利那現在主辦國慶晚會也是都一切都相當順利接下來就今年是十月十一號十天後的這個全國運動會那也是需要大家一起努力希望說能夠把這個防疫的這個作為還是要持續堅持因為這幾天上個禮拜的這個確診數比前一個禮拜下降了百分之二然後這個禮拜這幾天又前幾天那這樣的這個這個確診數又比上上禮拜又下降了百分之十以上所以說這個下降的趨勢希望能夠維持能夠把大家再辛苦一點讓登革日這個疫情早日平息民眾的生活早日回復安寧尤其接下來剛剛講的十月清零接下來全國運動會都有相當多的選手、觀眾到場比賽加油這個部分都是我們需要能夠給一個客人一個最賓士如歸、最舒適、最健康的環境也就是我們最近大家努力的目標尤其要給市民朋友們我們加強入戶的資金加強道路以及室內的一個防治作為也是希望說配合的種種的條件能夠讓一起能夠早日平息能夠讓市民朋友更健康感謝各位，謝謝，散會！你怎麼不說說'}\n"]}]},{"cell_type":"code","source":["!pip install download-youtube-subtitle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"GcB1wZ4Wpf5Q","executionInfo":{"status":"error","timestamp":1708502283432,"user_tz":-480,"elapsed":5,"user":{"displayName":"nctuhack3","userId":"16262766100182643838"}},"outputId":"fceedcc7-76a5-450c-aff3-81f17770475e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"A UTF-8 locale is required. Got ANSI_X3.4-1968","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-52802858c65b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install download-youtube-subtitle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}]},{"cell_type":"code","source":["!dl-youtube-cc bHcJCp2Fyxs  --remove_font_tag --save_to_file"],"metadata":{"id":"mo2mZJzwprQ7"},"execution_count":null,"outputs":[]}]}
